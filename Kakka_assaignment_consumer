import argparse
from confluent_kafka import Consumer
from confluent_kafka.serialization import SerializationContext, MessageField
from confluent_kafka.schema_registry.json_schema import JSONDeserializer
from confluent_kafka.schema_registry import SchemaRegistryClient
import cassandra
from cassandra.cluster import Cluster
from cassandra.auth import PlainTextAuthProvider

API_KEY = 'KI3UKMZVFHR72PPX'
ENDPOINT_SCHEMA_URL  = 'https://psrc-znpo0.ap-southeast-2.aws.confluent.cloud'
API_SECRET_KEY = '1WHoM+Rhb56T9+b1CnwIAHZBjSlqbJVQU+LFQxz6c+24aK+Mr/i1GfB2l3HW8vpE'
BOOTSTRAP_SERVER = 'pkc-l7pr2.ap-south-1.aws.confluent.cloud:9092'
SECURITY_PROTOCOL = 'SASL_SSL'
SSL_MACHENISM = 'PLAIN'
SCHEMA_REGISTRY_API_KEY = 'WIAZVKDD6D3EI3W4'
SCHEMA_REGISTRY_API_SECRET = 'DPkEt3ZvqKpAO3pVOiOkD519ezjrGYMXBt1B1qQf1Bnhq1yByZ2acozB1BFMAHv9'


def sasl_conf():

    sasl_conf = {'sasl.mechanism': SSL_MACHENISM,
                 # Set to SASL_SSL to enable TLS support.
                #  'security.protocol': 'SASL_PLAINTEXT'}
                'bootstrap.servers':BOOTSTRAP_SERVER,
                'security.protocol': SECURITY_PROTOCOL,
                'sasl.username': API_KEY,
                'sasl.password': API_SECRET_KEY
                }
    return sasl_conf



def schema_config():
    return {'url':ENDPOINT_SCHEMA_URL,
    
    'basic.auth.user.info':f"{SCHEMA_REGISTRY_API_KEY}:{SCHEMA_REGISTRY_API_SECRET}"

    }
class Employee:
    def __init__(self, record: dict):
        self.record = record

    @staticmethod
    def dict_to_emp(data:dict,ctx):
        return Employee(record=data)

#cassandra connection

cloud_config= {
  'secure_connect_bundle': 'D:\kafka\secure-connect-kakfa-assaignment.zip'
}
auth_provider = PlainTextAuthProvider('UdjJJQtqFLqlLmUyeWAgIIzE', 'NArq0Rt,AUk+IAP2nb216UoGENif5G9RZs0q-Hcu9BTpMlC-+h3zqw2c+_IAysjIKY-.n3ZfZDUyCmXXmwve.iDvO4Sjt,.bPqR-X1fucA6W3bCQmr5qew0iT7lREb8s')
cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)
session = cluster.connect()
session.set_keyspace('big_data')

table_query = """
    CREATE TABLE IF NOT EXISTS Kakfa_assaignment (
        message TEXT,
        value TEXT
    )
"""
#session.execute(table_query)



def main(topic):

    schema_registry_conf = schema_config()
    schema_registry_client = SchemaRegistryClient(schema_registry_conf)
    # subjects = schema_registry_client.get_subjects()
    # print(subjects)
    subject = topic+'-value'

    schema = schema_registry_client.get_latest_version(subject)
    schema_str=schema.schema.schema_str

    json_deserializer = JSONDeserializer(schema_str,from_dict=Employee.dict_to_emp)

    consumer_conf = sasl_conf()
    consumer_conf.update({
                     'group.id': 'group1',
                     'auto.offset.reset': "earliest"})

    consumer = Consumer(consumer_conf)
    consumer.subscribe([topic])


    while True:
        try:
            # SIGINT can't be handled when polling, limit timeout to 1 second.
            msg = consumer.poll(1.0)
            if msg is None:
                continue

            emp = json_deserializer(msg.value(), SerializationContext(msg.topic(), MessageField.VALUE))

            if emp is not None:
                query = f"INSERT INTO Kakfa_assaignment (message) VALUES ('{emp}')"
                session.execute(query)
                print("User record {}: emp: {}\n"
                      .format(msg.key(), emp))
        except KeyboardInterrupt:
            break

    consumer.close()

main("Employee_kafka")
